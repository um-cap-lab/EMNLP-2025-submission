{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Minicons Installation\n",
    "# Introduction can be found https://kanishka.xyz/post/minicons-running-large-scale-behavioral-analyses-on-transformer-lms/\n",
    "# Tutorial and code can be found https://github.com/kanishkamisra/minicons/blob/master/examples/surprisals.md\n",
    "#!pip install minicons\n",
    "\n",
    "from minicons import scorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#model_path = \"gpt2-small/checkpoint-pretrainedtokenizer_10M\"\n",
    "#model_path = \"gpt2-small/checkpoint-trainedtokenizer_10M\"\n",
    "#model_path = \"gpt2-small/checkpoint-trainedtokenizer_10M_whitespace\"\n",
    "#model_path = \"gpt2-small/checkpoint-pretrainedtokenizer_100M\"\n",
    "#model_path = \"gpt2-small/checkpoint-trainedtokenizer_100M\"\n",
    "model_path = \"gpt2-small/checkpoint-trainedtokenizer_100M_whitespace\"\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "# wrap with minicons scorer\n",
    "lm_scorer = scorer.IncrementalLMScorer(model_path, device = \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"Special tokens:\", tokenizer.all_special_tokens)\n",
    "print(\"Special token IDs:\", tokenizer.all_special_ids)\n",
    "print(\"Special tokens map:\", tokenizer.special_tokens_map)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Special tokens: ['<|endoftext|>']\n",
      "Special token IDs: [50257]\n",
      "Special tokens map: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "surprisals"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[('<pad>', 0.0),\n",
       "  ('ĠTheĠ', 6.771759033203125),\n",
       "  ('balloon', 12.995538711547852),\n",
       "  ('Ġwa', 3.036536693572998),\n",
       "  ('s', 0.0033515978138893843),\n",
       "  ('Ġinf', 14.873947143554688),\n",
       "  ('lat', 3.8473756313323975),\n",
       "  ('ingĠfor', 9.053845405578613),\n",
       "  ('Ġ10', 10.562509536743164),\n",
       "  ('Ġminute', 3.032411813735962),\n",
       "  ('s', 0.0010208890307694674)]]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def calculate_surprisal(sentence):\n",
    "    '''\n",
    "    Takes in a sentence, and outputs surprisal values for each word.\n",
    "    '''\n",
    "    input_sentence = sentence\n",
    "    # token_score() function of Minicons takes in several parameters\n",
    "    # if surprisal = True, the output value is surprisal instead of log likelihood\n",
    "    # if base_two = True, the log likelihood will be in base 2\n",
    "    # see Minicons documentations for details\n",
    "    # score tokens\n",
    "    token_surprisals = lm_scorer.token_score(input_sentence, surprisal = True, base_two = True)[0]\n",
    "    print(token_surprisals)\n",
    "\n",
    "\n",
    "    # filter out special tokens (like <pad>)\n",
    "    special_tokens = set(tokenizer.all_special_tokens + ['<pad>'])\n",
    "    filtered = [\n",
    "        (token, score)\n",
    "        for (token, score) in token_surprisals\n",
    "        if token not in special_tokens\n",
    "    ]\n",
    "\n",
    "   # expand tokens that contain multiple words\n",
    "    expanded = []\n",
    "    for token, score in token_surprisals:\n",
    "    #for token, score in filtered:\n",
    "        token = token.strip('Ġ') # remove space marker\n",
    "        if token.count('Ġ') > 0:\n",
    "            # multiple words inside\n",
    "            words = token.split('Ġ')\n",
    "            words = [word for word in words if word]  # remove empty strings\n",
    "            for i, word in enumerate(words):\n",
    "                expanded_token = word\n",
    "                expanded.append((expanded_token, score / len(words)))  # split surprisal equally\n",
    "        else:\n",
    "            expanded.append((token, score))    \n",
    "    #print(expanded)\n",
    "\n",
    "    # use regex to split into words and punctuation\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', sentence)\n",
    "    results = []\n",
    "\n",
    "    token_pointer = 0\n",
    "\n",
    "    for word in words:\n",
    "        accumulated = ''\n",
    "        word_surprisal = 0.0\n",
    "\n",
    "        while token_pointer < len(expanded):\n",
    "            token, surprisal = expanded[token_pointer]\n",
    "            accumulated += token\n",
    "            word_surprisal += surprisal\n",
    "            token_pointer += 1\n",
    "\n",
    "            if accumulated == word:\n",
    "                results.append((word, word_surprisal))\n",
    "                break\n",
    "        else:\n",
    "            results.append((word, word_surprisal))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "sentence = 'I know that your friend gave a baguette to Mary last weekend.'\n",
    "calculate_surprisal(sentence)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('I', 0.0), ('know', 4.365269184112549), ('that', 3.4667656421661377), ('your', 9.112505912780762), ('friend', 6.371501922607422), ('gave', 10.674038887023926), ('a', 4.927915096282959), ('bag', 9.063486099243164), ('u', 15.337505340576172), ('ette', 13.791769981384277), ('to', 5.820535182952881), ('Mary', 13.028478622436523), ('last', 11.46209716796875), ('weekend', 7.374884128570557), ('.', 2.0132205486297607)]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('I', 0.0),\n",
       " ('know', 4.365269184112549),\n",
       " ('that', 3.4667656421661377),\n",
       " ('your', 9.112505912780762),\n",
       " ('friend', 6.371501922607422),\n",
       " ('gave', 10.674038887023926),\n",
       " ('a', 4.927915096282959),\n",
       " ('baguette', 38.19276142120361),\n",
       " ('to', 5.820535182952881),\n",
       " ('Mary', 13.028478622436523),\n",
       " ('last', 11.46209716796875),\n",
       " ('weekend', 7.374884128570557),\n",
       " ('.', 2.0132205486297607)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def calculate_sentence_surprisal(word_surprisals):\n",
    "    \"\"\"Returns total surprisal and average surprisal per word.\"\"\"\n",
    "    scores = [score for word, score in word_surprisals]\n",
    "    total = sum(scores)\n",
    "    avg = total / len(scores)\n",
    "    return total, avg\n",
    "\n",
    "\n",
    "def compute_wh_licensing_interaction(sentences):\n",
    "    \"\"\"\n",
    "    sentences: dict with keys\n",
    "        'fg' = +Filler, +Gap\n",
    "        'fng' = +Filler, −Gap\n",
    "        'nfg' = −Filler, +Gap\n",
    "        'nfng' = −Filler, −Gap\n",
    "    Each value is a sentence string.\n",
    "\n",
    "    Returns:\n",
    "        A dict with total surprisal per sentence,\n",
    "        average surprisals per sentence,\n",
    "        and the wh-licensing interaction score.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    for key, sentence in sentences.items():\n",
    "        word_surprisals = calculate_surprisal(sentence)\n",
    "        total, avg = calculate_sentence_surprisal(word_surprisals)\n",
    "        scores[key] = {'total': total, 'avg': avg, 'details': word_surprisals}\n",
    "\n",
    "    # compute wh-licensing interaction\n",
    "    interaction = (\n",
    "        (scores['fng']['total'] - scores['nfng']['total']) -\n",
    "        (scores['fg']['total'] - scores['nfg']['total'])\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'scores': scores,\n",
    "        'interaction': interaction\n",
    "    }\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Statistical Analysis: Mixed-Effects Linear Regression Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "sentence_df = pd.read_csv('test_sentences/Double Gap Construction.csv')\n",
    "sentence_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>filler</th>\n",
       "      <th>gap</th>\n",
       "      <th>subject_gap</th>\n",
       "      <th>object_gap</th>\n",
       "      <th>prefix</th>\n",
       "      <th>licensor</th>\n",
       "      <th>subj</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>modifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>James realized</td>\n",
       "      <td>that</td>\n",
       "      <td>the dog</td>\n",
       "      <td>chased</td>\n",
       "      <td>the cat</td>\n",
       "      <td>through the yard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>James realized</td>\n",
       "      <td>that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chased</td>\n",
       "      <td>the cat</td>\n",
       "      <td>through the yard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>James realized</td>\n",
       "      <td>that</td>\n",
       "      <td>the dog</td>\n",
       "      <td>chased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>through the yard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>James realized</td>\n",
       "      <td>that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>through the yard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>James realized</td>\n",
       "      <td>what</td>\n",
       "      <td>the dog</td>\n",
       "      <td>chased</td>\n",
       "      <td>the cat</td>\n",
       "      <td>through the yard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>20</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The principal knows</td>\n",
       "      <td>that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>helped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after the exam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>20</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The principal knows</td>\n",
       "      <td>what</td>\n",
       "      <td>the counselor</td>\n",
       "      <td>helped</td>\n",
       "      <td>the student</td>\n",
       "      <td>after the exam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The principal knows</td>\n",
       "      <td>what</td>\n",
       "      <td>NaN</td>\n",
       "      <td>helped</td>\n",
       "      <td>the student</td>\n",
       "      <td>after the exam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>20</td>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The principal knows</td>\n",
       "      <td>what</td>\n",
       "      <td>the counselor</td>\n",
       "      <td>helped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after the exam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>20</td>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The principal knows</td>\n",
       "      <td>what</td>\n",
       "      <td>NaN</td>\n",
       "      <td>helped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after the exam.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_id condition  filler  gap  subject_gap  object_gap  \\\n",
       "0          1         a       0    0            0           0   \n",
       "1          1         b       0    1            1           0   \n",
       "2          1         c       0    1            0           1   \n",
       "3          1         d       0    1            1           1   \n",
       "4          1         e       1    0            0           0   \n",
       "..       ...       ...     ...  ...          ...         ...   \n",
       "155       20         d       0    1            1           1   \n",
       "156       20         e       1    0            0           0   \n",
       "157       20         f       1    1            1           0   \n",
       "158       20         g       1    1            0           1   \n",
       "159       20         h       1    1            1           1   \n",
       "\n",
       "                  prefix licensor           subj    verb       object  \\\n",
       "0         James realized     that        the dog  chased      the cat   \n",
       "1         James realized     that            NaN  chased      the cat   \n",
       "2         James realized     that        the dog  chased          NaN   \n",
       "3         James realized     that            NaN  chased          NaN   \n",
       "4         James realized     what        the dog  chased      the cat   \n",
       "..                   ...      ...            ...     ...          ...   \n",
       "155  The principal knows     that            NaN  helped          NaN   \n",
       "156  The principal knows     what  the counselor  helped  the student   \n",
       "157  The principal knows     what            NaN  helped  the student   \n",
       "158  The principal knows     what  the counselor  helped          NaN   \n",
       "159  The principal knows     what            NaN  helped          NaN   \n",
       "\n",
       "              modifier  \n",
       "0    through the yard.  \n",
       "1    through the yard.  \n",
       "2    through the yard.  \n",
       "3    through the yard.  \n",
       "4    through the yard.  \n",
       "..                 ...  \n",
       "155    after the exam.  \n",
       "156    after the exam.  \n",
       "157    after the exam.  \n",
       "158    after the exam.  \n",
       "159    after the exam.  \n",
       "\n",
       "[160 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# columns: set_id (indicates sentence set), wh_licensor (0/1), gap (0/1), island_presence (0 = non-island, 1 = island), island_type, surprisal\n",
    "sentence_df = pd.read_csv('test_construction.csv')\n",
    "sentence_df['wh_licensor'] = sentence_df['wh_licensor'].astype('category')\n",
    "sentence_df['gap'] = sentence_df['gap'].astype('category')\n",
    "sentence_df['island_presence'] = sentence_df['island_presence'].astype('category')\n",
    "sentence_df['island_type'] = sentence_df['island_type'].astype('category')\n",
    "\n",
    "# list to store results\n",
    "interaction_results = []\n",
    "\n",
    "# a region filtering step is probably needed here\n",
    "region_df = sentence_df[sentence_df['region'] == '']\n",
    "\n",
    "def mixed_effects_linear_regression(df, label):\n",
    "    '''\n",
    "    Fits mixed-effects model and extracts wh-licensing interaction.\n",
    "    '''\n",
    "    model = smf.mixedlm(\n",
    "        \"surprisal ~ wh_licensor * gap * island_type\",\n",
    "        df,\n",
    "        groups = df[\"set_id\"],\n",
    "        re_formula = \"~wh_licensor + gap + island_type\"\n",
    ")\n",
    "\n",
    "    result = model.fit()\n",
    "    interaction_coef = result.params.get('wh_licensor[T.1]:gap[T.1]', None)\n",
    "    \n",
    "    print(f\"\\n=== {label.upper()} ===\")\n",
    "    print(result.summary())\n",
    "    \n",
    "    return interaction_coef\n",
    "\n",
    "\n",
    "interaction = mixed_effects_linear_regression(region_df, \"construction_type\") # label name to be changed according to construction type"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}